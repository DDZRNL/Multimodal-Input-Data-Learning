{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "799af4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "import multiprocessing as mp\n",
    "\n",
    "import tqdm\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.model_selection as skms\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc92a65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "719ccd7e",
   "metadata": {},
   "source": [
    "# Building Attributes Only Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee58c792",
   "metadata": {},
   "source": [
    "Be sure to have \"image_class_labels.txt\" and \"image_attribute_labels.txt\" in the same directory as this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "50ae9945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attributes Only Dataset \n",
    "class BirdAttributesDataset(Dataset):\n",
    "    def __init__(self, attributes, labels):\n",
    "        self.labels = labels\n",
    "        self.attributes = attributes\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        label = self.labels[idx]\n",
    "        attribute = self.attributes[idx]\n",
    "        #sample = {\"Attribute\": attribute, \"Label\": label}\n",
    "        #return sample\n",
    "        return attribute, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7b20e126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Attributes Data and Labels\n",
    "attr_data = np.loadtxt(\"image_attribute_labels.txt\", delimiter=' ',dtype=float, usecols=(0,1,2))\n",
    "image_id_attr = attr_data[:,0]\n",
    "attributes_id = attr_data[:,1]\n",
    "existences = attr_data[:,2]\n",
    "\n",
    "img_data = np.loadtxt(\"image_class_labels.txt\", delimiter=' ', dtype=float, usecols=(0,1))\n",
    "image_id_label = img_data[:,0]\n",
    "class_labels = img_data[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cb43779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining into a useable dataset\n",
    "# Give each attribute data the label of its class\n",
    "img_existence_data = list()\n",
    "prev_label = image_id_attr[0]\n",
    "curr_existence = list()\n",
    "for i in range(len(existences)):\n",
    "    this_label = image_id_attr[i]\n",
    "    # Check to see if we are done with an image_id\n",
    "    if(this_label != prev_label):\n",
    "        img_existence_data.append(curr_existence)\n",
    "        curr_existence = list()\n",
    "        curr_existence.append(existences[i])\n",
    "    else:\n",
    "        curr_existence.append(existences[i])\n",
    "    prev_label = this_label     \n",
    "# Appending last values\n",
    "img_existence_data.append(curr_existence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "12352b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = img_existence_data\n",
    "labels = class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "83fd4a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find top 10 classes\n",
    "class_freq = np.zeros(200)\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    class_freq[int(labels[i])-1] += 1\n",
    "    \n",
    "sorted_classes = np.argsort(class_freq)\n",
    "top_10_classes = sorted_classes[-11:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f0669f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only top 10 classes\n",
    "labels_top_10 = []\n",
    "attributes_top_10 = []\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] in top_10_classes:\n",
    "        labels_top_10.append(labels[i])\n",
    "        attributes_top_10.append(attributes[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3686b8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[78 79 80 81 82 84 85 86 87 89]\n",
      "592\n",
      "592\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n"
     ]
    }
   ],
   "source": [
    "print(top_10_classes)\n",
    "print(len(labels_top_10))\n",
    "print(len(attributes_top_10))\n",
    "\n",
    "labels_normalized = []\n",
    "# normalize labels\n",
    "curr_label = labels_top_10[0]\n",
    "curr_norm = 1\n",
    "for i in range(len(labels_top_10)):\n",
    "    if (labels_top_10[i] != curr_label):\n",
    "        # new label\n",
    "        curr_norm += 1\n",
    "        curr_label = labels_top_10[i]\n",
    "        labels_normalized.append(curr_norm)\n",
    "    else:\n",
    "        # same label\n",
    "        labels_normalized.append(curr_norm)\n",
    "        \n",
    "        \n",
    "labels = labels_normalized\n",
    "attributes = attributes_top_10\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fed477a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.DataFrame({'Attributes': attributes, 'Labels': labels})\n",
    "AD = BirdAttributesDataset(labels_df['Attributes'], labels_df['Labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "28807c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_indices, test_indices = train_test_split(list(range(len(AD))), test_size=0.3, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "00151c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.utils.data.Subset(AD, train_indices)\n",
    "test_data = torch.utils.data.Subset(AD, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b0fde6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=8, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ed96e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28c78c7a",
   "metadata": {},
   "source": [
    "# Training and  Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d7dfcc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "288ac291",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, attribute_dim, n_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = nn.Linear(attribute_dim, 8)\n",
    "        self.output = nn.Linear(8, n_classes)\n",
    "        self.double()\n",
    "\n",
    "    def forward(self, attributes):\n",
    "        attributes = torch.sigmoid(self.hidden(attributes))\n",
    "        output = self.output(attributes)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2b968533",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10\n",
    "attribute_dim = len(attributes[0])\n",
    "n_classes = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "708ba3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, trainloader, optimizer, loss_fn, num_epochs=NUM_EPOCHS):\n",
    "    # Put the network in training mode\n",
    "    net.train()\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        running_loss = 0.0\n",
    "        t = tqdm(trainloader, desc='Epoch: 0, Loss: 0.0', position = 0, leave=True)\n",
    "        \n",
    "        for i, data in enumerate(trainloader):\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "            #print(len(inputs))\n",
    "            #print(inputs[0])\n",
    "            #print(len(inputs[0]))\n",
    "            inputs = torch.transpose(torch.stack(inputs),0,1)\n",
    "            optimizer.zero_grad() # zeroes gradients\n",
    "            \n",
    "            outputs = net.forward(inputs) # forward pass\n",
    "            #print(labels)\n",
    "            labels = labels.type(torch.LongTensor)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward() # backward pass\n",
    "            optimizer.step() # weight updates\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            t.set_description(f'Epoch: {epoch+1}/{NUM_EPOCHS}, Loss: {running_loss/(i+1):.4f}', refresh=True)\n",
    "            t.update()\n",
    "            t.refresh()\n",
    "            \n",
    "            \n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "de294e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(net, data_loader, criterion, name=''):\n",
    "    # set the network to evaluation mode\n",
    "    net.eval()\n",
    "    accuracy = 0\n",
    "    loss = 0\n",
    "    num_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(data_loader):\n",
    "            inputs, labels = data\n",
    "            inputs = torch.transpose(torch.stack(inputs),0,1)\n",
    "            labels = labels.type(torch.LongTensor)\n",
    "            out = net(inputs)\n",
    "            loss_fn = criterion(out, labels)\n",
    "            loss += loss_fn.item()\n",
    "            accuracy += (out.argmax(dim=1) == labels).sum()\n",
    "            num_samples += inputs.shape[0]\n",
    "    loss = loss/num_samples\n",
    "    accuracy = accuracy/num_samples\n",
    "    print(\"Test Loss: {:.6f} \\tAccuracy: {:.6f}\".format(loss, accuracy))\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3f7d3ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f0235b25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100, Loss: 2.3914: 100%|█████████████████████████████████████████████████████| 52/52 [00:00<00:00, 274.72it/s]\n",
      "Epoch: 2/100, Loss: 2.3482: 100%|█████████████████████████████████████████████████████| 52/52 [00:00<00:00, 267.64it/s]\n",
      "Epoch: 3/100, Loss: 2.3101: 100%|█████████████████████████████████████████████████████| 52/52 [00:00<00:00, 269.82it/s]\n",
      "Epoch: 4/100, Loss: 2.2782: 100%|█████████████████████████████████████████████████████| 52/52 [00:00<00:00, 270.66it/s]\n",
      "Epoch: 5/100, Loss: 2.2479: 100%|█████████████████████████████████████████████████████| 52/52 [00:00<00:00, 276.43it/s]\n",
      "Epoch: 6/100, Loss: 2.2196: 100%|█████████████████████████████████████████████████████| 52/52 [00:00<00:00, 276.44it/s]\n",
      "Epoch: 7/100, Loss: 2.1932: 100%|█████████████████████████████████████████████████████| 52/52 [00:00<00:00, 269.71it/s]\n",
      "Epoch: 8/100, Loss: 2.1679: 100%|█████████████████████████████████████████████████████| 52/52 [00:00<00:00, 267.83it/s]\n",
      "Epoch: 9/100, Loss: 2.1427: 100%|█████████████████████████████████████████████████████| 52/52 [00:00<00:00, 269.48it/s]\n",
      "Epoch: 10/100, Loss: 2.1167: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 267.67it/s]\n",
      "Epoch: 11/100, Loss: 2.0921: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 264.69it/s]\n",
      "Epoch: 12/100, Loss: 2.0671: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 272.71it/s]\n",
      "Epoch: 13/100, Loss: 2.0420: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 259.41it/s]\n",
      "Epoch: 14/100, Loss: 2.0176: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 267.70it/s]\n",
      "Epoch: 15/100, Loss: 1.9921: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 268.63it/s]\n",
      "Epoch: 16/100, Loss: 1.9667: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 274.65it/s]\n",
      "Epoch: 17/100, Loss: 1.9421: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 272.97it/s]\n",
      "Epoch: 18/100, Loss: 1.9177: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 268.28it/s]\n",
      "Epoch: 19/100, Loss: 1.8930: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 254.92it/s]\n",
      "Epoch: 20/100, Loss: 1.8680: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 273.44it/s]\n",
      "Epoch: 21/100, Loss: 1.8442: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 261.38it/s]\n",
      "Epoch: 22/100, Loss: 1.8199: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 268.74it/s]\n",
      "Epoch: 23/100, Loss: 1.7951: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 273.03it/s]\n",
      "Epoch: 24/100, Loss: 1.7698: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 262.24it/s]\n",
      "Epoch: 25/100, Loss: 1.7447: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 258.78it/s]\n",
      "Epoch: 26/100, Loss: 1.7222: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 258.85it/s]\n",
      "Epoch: 27/100, Loss: 1.6970: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 260.24it/s]\n",
      "Epoch: 28/100, Loss: 1.6731: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 259.77it/s]\n",
      "Epoch: 29/100, Loss: 1.6492: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 250.80it/s]\n",
      "Epoch: 30/100, Loss: 1.6266: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 259.95it/s]\n",
      "Epoch: 31/100, Loss: 1.6032: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 261.69it/s]\n",
      "Epoch: 32/100, Loss: 1.5789: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 262.65it/s]\n",
      "Epoch: 33/100, Loss: 1.5557: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 256.76it/s]\n",
      "Epoch: 34/100, Loss: 1.5346: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 255.43it/s]\n",
      "Epoch: 35/100, Loss: 1.5139: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 266.50it/s]\n",
      "Epoch: 36/100, Loss: 1.4908: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 260.77it/s]\n",
      "Epoch: 37/100, Loss: 1.4684: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 255.32it/s]\n",
      "Epoch: 38/100, Loss: 1.4479: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 270.43it/s]\n",
      "Epoch: 39/100, Loss: 1.4269: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 259.15it/s]\n",
      "Epoch: 40/100, Loss: 1.4055: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 268.87it/s]\n",
      "Epoch: 41/100, Loss: 1.3830: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 265.51it/s]\n",
      "Epoch: 42/100, Loss: 1.3641: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 265.94it/s]\n",
      "Epoch: 43/100, Loss: 1.3460: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 274.21it/s]\n",
      "Epoch: 44/100, Loss: 1.3246: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 268.89it/s]\n",
      "Epoch: 45/100, Loss: 1.3061: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 264.68it/s]\n",
      "Epoch: 46/100, Loss: 1.2870: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 259.07it/s]\n",
      "Epoch: 47/100, Loss: 1.2675: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 265.94it/s]\n",
      "Epoch: 48/100, Loss: 1.2493: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 267.02it/s]\n",
      "Epoch: 49/100, Loss: 1.2299: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 257.48it/s]\n",
      "Epoch: 50/100, Loss: 1.2128: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 267.55it/s]\n",
      "Epoch: 51/100, Loss: 1.1959: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 264.59it/s]\n",
      "Epoch: 52/100, Loss: 1.1792: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 262.00it/s]\n",
      "Epoch: 53/100, Loss: 1.1591: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 265.69it/s]\n",
      "Epoch: 54/100, Loss: 1.1430: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 251.64it/s]\n",
      "Epoch: 55/100, Loss: 1.1260: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 249.43it/s]\n",
      "Epoch: 56/100, Loss: 1.1108: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 255.21it/s]\n",
      "Epoch: 57/100, Loss: 1.0949: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 256.73it/s]\n",
      "Epoch: 58/100, Loss: 1.0798: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 247.35it/s]\n",
      "Epoch: 59/100, Loss: 1.0626: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 262.95it/s]\n",
      "Epoch: 60/100, Loss: 1.0481: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 257.55it/s]\n",
      "Epoch: 61/100, Loss: 1.0340: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 272.23it/s]\n",
      "Epoch: 62/100, Loss: 1.0187: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 267.84it/s]\n",
      "Epoch: 63/100, Loss: 1.0040: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 263.13it/s]\n",
      "Epoch: 64/100, Loss: 0.9886: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 257.64it/s]\n",
      "Epoch: 65/100, Loss: 0.9752: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 270.88it/s]\n",
      "Epoch: 66/100, Loss: 0.9601: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 267.51it/s]\n",
      "Epoch: 67/100, Loss: 0.9466: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 267.72it/s]\n",
      "Epoch: 68/100, Loss: 0.9336: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 260.01it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 69/100, Loss: 0.9208: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 266.18it/s]\n",
      "Epoch: 70/100, Loss: 0.9087: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 273.76it/s]\n",
      "Epoch: 71/100, Loss: 0.8949: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 279.47it/s]\n",
      "Epoch: 72/100, Loss: 0.8825: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 275.37it/s]\n",
      "Epoch: 73/100, Loss: 0.8709: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 269.16it/s]\n",
      "Epoch: 74/100, Loss: 0.8572: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 269.61it/s]\n",
      "Epoch: 75/100, Loss: 0.8472: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 275.08it/s]\n",
      "Epoch: 76/100, Loss: 0.8343: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 271.30it/s]\n",
      "Epoch: 77/100, Loss: 0.8234: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 267.78it/s]\n",
      "Epoch: 78/100, Loss: 0.8122: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 271.20it/s]\n",
      "Epoch: 79/100, Loss: 0.8006: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 265.55it/s]\n",
      "Epoch: 80/100, Loss: 0.7883: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 274.14it/s]\n",
      "Epoch: 81/100, Loss: 0.7781: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 270.68it/s]\n",
      "Epoch: 82/100, Loss: 0.7673: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 265.24it/s]\n",
      "Epoch: 83/100, Loss: 0.7555: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 270.30it/s]\n",
      "Epoch: 84/100, Loss: 0.7458: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 271.73it/s]\n",
      "Epoch: 85/100, Loss: 0.7366: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 270.88it/s]\n",
      "Epoch: 86/100, Loss: 0.7270: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 280.07it/s]\n",
      "Epoch: 87/100, Loss: 0.7172: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 278.69it/s]\n",
      "Epoch: 88/100, Loss: 0.7065: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 276.46it/s]\n",
      "Epoch: 89/100, Loss: 0.6980: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 273.66it/s]\n",
      "Epoch: 90/100, Loss: 0.6869: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 277.49it/s]\n",
      "Epoch: 91/100, Loss: 0.6775: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 272.27it/s]\n",
      "Epoch: 92/100, Loss: 0.6682: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 278.23it/s]\n",
      "Epoch: 93/100, Loss: 0.6582: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 274.55it/s]\n",
      "Epoch: 94/100, Loss: 0.6519: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 276.70it/s]\n",
      "Epoch: 95/100, Loss: 0.6413: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 268.86it/s]\n",
      "Epoch: 96/100, Loss: 0.6332: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 271.16it/s]\n",
      "Epoch: 97/100, Loss: 0.6242: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 277.05it/s]\n",
      "Epoch: 98/100, Loss: 0.6171: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 277.00it/s]\n",
      "Epoch: 99/100, Loss: 0.6085: 100%|████████████████████████████████████████████████████| 52/52 [00:00<00:00, 269.31it/s]\n",
      "Epoch: 100/100, Loss: 0.5988: 100%|███████████████████████████████████████████████████| 52/52 [00:00<00:00, 272.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "net = Net(attribute_dim, n_classes)\n",
    "LR = 0.0005\n",
    "optimizer = torch.optim.AdamW(net.parameters(), lr=LR)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train(net, train_loader, optimizer, criterion, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2e6bdd63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 574.88it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.105567 \tAccuracy: 0.780899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluating Net\n",
    "test_loss, accuracy = eval(net, test_loader , criterion, 'Attributes test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dbf1c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffd3ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
